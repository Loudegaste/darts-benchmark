{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Darts benchamrk \n",
    "\n",
    "This notebook showcases tools developed for benchmarking the different forecasting models in Darts, which could be useful for other developers.\n",
    "We will showcase:\n",
    "\n",
    "**Auto-ML with Optuna and raytune**: hyperparameter tuning with predefined broad parameter space for all model supported<br />\n",
    "**Illustrate**: A function to visualise the behavior of different darts models on a dataset <br />\n",
    "**Experiment**: A function to perform cross comparison of a list of models on a list of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install dependencies\n",
    "!pip install -q git+https://github.com/Loudegaste/darts-benchmark\n",
    "\n",
    "from darts_benchmark.benchmark_tools import Dataset, experiment, silence_prompt, illustrate\n",
    "from darts_benchmark.model_evaluation import evaluate_model\n",
    "from darts_benchmark.model_evaluation import set_randommness\n",
    "from darts.models import NaiveSeasonal, NHiTSModel, Prophet, NLinearModel\n",
    "from darts.utils import missing_values\n",
    "from darts_benchmark.optuna_search import optuna_search\n",
    "from darts.datasets import AirPassengersDataset, WeatherDataset\n",
    "from darts.metrics import mae\n",
    "\n",
    "set_randommness(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading\n",
    "To ensure a uniform structure for the data loading, each dataset must be contained in a ```benchmark_tools.Dataset``` Named tuple with the following fields:\n",
    "\n",
    "**name**: Dataset name for display<br />\n",
    "**series**: A darts.timeseries object<br />\n",
    "**future_covariates**:(Optional) future covariates used as support for the forecast<br />\n",
    "**past_covariates**:(Optional) past covariates used as support for the forecast<br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Preparing two datasets: Air passengers and Weather\n",
    "\n",
    "air_pass_series = missing_values.fill_missing_values(AirPassengersDataset().load())\n",
    "weather_ds = missing_values.fill_missing_values(WeatherDataset().load().resample(\"1h\"))[\n",
    "    -1500:\n",
    "]\n",
    "weather_past_cov = weather_ds[\n",
    "    [\"p (mbar)\", \"wv (m/s)\", \"wd (deg)\", \"rain (mm)\", \"raining (s)\", \"SWDR (W/mÂ²)\"]\n",
    "]\n",
    "weather_series = weather_ds[\"T (degC)\"]\n",
    "\n",
    "dataset_air_passengers = Dataset(name=\"Air passengers\", series=air_pass_series)\n",
    "dataset_weather = Dataset(\n",
    "    name=\"Weather\", series=weather_series, past_covariates=weather_past_cov\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Hyperparameter search using optuna and raytune\n",
    "\n",
    "The function ```optuna_search.optuna_search``` implements a hyperparameter search for the provided model on the provided dataset. For the search, the function will lookup the hyper parameter space from ```optuna_search/param_space.py```. \n",
    "\n",
    "In param_space.py, for each model supported, there will be:\n",
    "* **fixed_params_\"modelname\" function:** it defines default parameters for the model\n",
    "* **optuna_params_\"modelname\" function:** it defines the parameter space for optuna too search.\n",
    "\n",
    "To add support for another model, simply add the corresponding 2 functions for the desired model and add the function to the ditionnary lookup at the end of the param_space.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Hyperparameter search using optuna and raytune\n",
    "\n",
    "silence_prompt()\n",
    "model_class = NLinearModel\n",
    "time_budget = 60\n",
    "forecast_horizon = 5\n",
    "split = 0.75\n",
    "\n",
    "best_params_60sec = optuna_search(\n",
    "    model_class=model_class, \n",
    "    dataset=dataset_air_passengers,\n",
    "    time_budget=time_budget,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    scale_data=True,\n",
    ")\n",
    "\n",
    "# display the output after hyperparameter search\n",
    "error_60sec, forecasts_60sec = evaluate_model( # type: ignore\n",
    "    model_class, dataset_air_passengers.series,\n",
    "    model_params=best_params_60sec,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    split=split,\n",
    "    get_output_sample=True,\n",
    ")\n",
    "\n",
    "error_default, forecasts_default = evaluate_model( # type: ignore\n",
    "    model_class, dataset_air_passengers.series,\n",
    "    model_params=None,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    split=split,\n",
    "    get_output_sample=True,\n",
    ")\n",
    "\n",
    "dataset_air_passengers.series.plot(label=\"actual\")\n",
    "forecasts_default.plot(label=f\"prediction_default\\nerror={error_default:.2f}\")\n",
    "forecasts_60sec.plot(label=f\"prediction_60sec\\nerror={error_60sec:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model comparison\n",
    "\n",
    "To compare visually the performance of different models on a dataset, the ```benchmark_tools.illustrate``` function fits and plots multiple models in a standardized way. With ```grid_search=True``` and ```time_budget: int```, the ```illustrate``` function will first perform an optuna hyperparameter search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Model comparison\n",
    "illustrate(models=[NaiveSeasonal, NHiTSModel, Prophet, NLinearModel], \n",
    "           dataset=dataset_air_passengers, \n",
    "           forecast_horizon=5, grid_search=False, \n",
    "           silent_search=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Experiment\n",
    "\n",
    "To run a full scale comparison of multiple models on multiple datasets, the ```benchmark_tools.experiment``` function fits and evaluates a list of models on alist of datasets. With ```grid_search=True``` and ```time_budget: int```, the ```experiment``` function will first perform an optuna hyperparameter search for each model/dataset combinaison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = experiment(\n",
    "    list_datasets=[dataset_air_passengers, dataset_weather],\n",
    "    models=[NaiveSeasonal, NHiTSModel, Prophet],\n",
    "    grid_search=False,\n",
    "    forecast_horizon=0.01, # the forecast horizon will be set to 1% of the time series length\n",
    "    repeat=3,\n",
    "    silent_search=True,\n",
    ")\n",
    "\n",
    "print(\"\\n\\n\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('env_name')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50106990e21d8b339b0d75f8ec00afb89c4ab0e971fb68456134876e1b48d47c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
